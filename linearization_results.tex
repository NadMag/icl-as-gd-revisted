\begin{table*}[t]
	\centering
	\subfloat{
		\begin{tabular}{|l|cccc|c|}
			\hline \textbf{Metric $\textbackslash$ Task} & SST2   & SST5   & MR     & Subj  & Average        \\
			\hline SimAOU Random                         & 0.001  & 0.002  & 0.001  & 0.002 & 0.002          \\
			\hline SimAOU FT                             & 0.1091 & 0.113  & 0.219  & 0.193 & \textbf{0.158} \\
			\hline SimAOU Lin FT                         & 0.122  & 0.0789 & 0.171  & 0.148 & 0.130          \\
			\hline
		\end{tabular}
	}
	\quad

	\subfloat{
		\begin{tabular}{|l|cccc|c|}
			\hline \textbf{Metric $\textbackslash$ Task} & SST2   & SST5   & MR    & Subj  & Average        \\
			\hline SimAM                       & 0.5547 & 0.3914 & 0.398 & 0.378 & 0.430          \\
			\hline SimAM FT                        & 0.585  & 0.404  & 0.498 & 0.487 & \textbf{0.493} \\
			\hline SimAM Lin FT                    & 0.573  & 0.403  & 0.448 & 0.449 & 0.468          \\
			\hline
		\end{tabular}
	}

	\caption{SimAOU and SimAM on four datasets, comparing similarity between random and finetune for both original model and linearization of the model.}
	\label{tabel:lin_results}
\end{table*}

We calculated SimAOU and SimAM for both original and linearized models. Results are shown in Table \ref{tabel:lin_results}.
In addition we were unable evaluate the linearized model on the datasets AGNews and CB due to heavy memory consumption. 
The results indicate that the linearized model yields lower similarity scores compared to the original model but significantly higher scores than a random vector. This suggests that our hypothesis was incorrect and other simple model versions should be thought of. More on that in the discussion section.
