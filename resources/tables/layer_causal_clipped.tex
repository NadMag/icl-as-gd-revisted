\begin{table*}[th]
	\centering
	\setlength{\tabcolsep}{7pt}
		\begin{tabular}{l | c}
		\toprule
		& \textbf{Subj} \\
		\midrule
		 SimAUO (Standard FT)     & 0.1932 \\
		 SimAUO (LC-FT Clipped)   & \textbf{0.3480}  \\
		\midrule
		 SimAM (ZSL)                     & 0.3786 \\
		 SimAM (Standard FT)             & \textbf{0.4870} \\
		 SimAM (LC-FT Clipped)           & 0.4227 \\
		
		\end{tabular}
	\caption{
		% Left shows the results for the per-layer training process. Middle shows the results for the per-layer training process with gradient norm clipping. Right shows the results for the standard fine-tuning process.
		Comparison of layer-causal finetuning with gradient norm clipping (clipped to 12.0 in $\ell_\infty$ norm).
		This results show that even arbitrary clipping may resolve the drop in SimAM shown in table \ref{tab:layer_causal}.
	}
	\label{tab:per_layer_clipping_metrics}
\end{table*}